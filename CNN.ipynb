{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83bf3ea4-32a3-4316-aa21-eb7a60bc9538",
   "metadata": {
    "id": "83bf3ea4-32a3-4316-aa21-eb7a60bc9538"
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc98d86-ea1d-431a-9a8d-97ba7bc56ee7",
   "metadata": {
    "id": "fbc98d86-ea1d-431a-9a8d-97ba7bc56ee7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# using tensorflow to select models, optimzers their characteristics\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.metrics import cohen_kappa_score, jaccard_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split #to split dataset into 3 parts\n",
    "import json\n",
    "import numpy as np   #  to perform mathematic operations\n",
    "import cv2   # to perform opencv operations\n",
    "import os   # to navigate through paths of a file\n",
    "import time\n",
    "import matplotlib.pyplot as plt   #to display images\n",
    "from PIL import Image   #to display images\n",
    "import copy\n",
    "import h5py\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "#from lr_utils import load_dataset\n",
    "#from public_tests import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea94904a-c632-470d-910c-8477c4108f55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea94904a-c632-470d-910c-8477c4108f55",
    "outputId": "c856816b-96f8-4a7d-d18d-52da07ddea04"
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68972d16-152d-48b3-a0fc-b2c750fc65eb",
   "metadata": {
    "id": "68972d16-152d-48b3-a0fc-b2c750fc65eb"
   },
   "source": [
    "# Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c53298-0ecd-4766-94e9-2ed244ad148a",
   "metadata": {
    "id": "92c53298-0ecd-4766-94e9-2ed244ad148a"
   },
   "outputs": [],
   "source": [
    "#!unzip /content/BreaKHis_v2.zip\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_dir = 'C:/Users/IIOT CAD/Documents/Meet/BreaKHis_v1'\n",
    "\n",
    "# list of class labels (categories)\n",
    "categories = [\"adenosis\", \"fibroadenoma\", \"phyllodes_tumor\", \"tubular_adenoma\", \"ductal_carcinoma\", \"lobular_carcinoma\", \"mucinous_carcinoma\", \"papillary_carcinoma\"]\n",
    "\n",
    "# dictionary to map category names to numeric labels\n",
    "category_to_label = {category: label for label, category in enumerate(categories)}\n",
    "\n",
    "# Lists to store images and corresponding labels\n",
    "dataset = []\n",
    "labels = []\n",
    "\n",
    "# the target size for resizing the images\n",
    "target_size = (224, 224)  \n",
    "\n",
    "# Looping through each category\n",
    "for category in categories:\n",
    "    category_dir = os.path.join(data_dir, category)\n",
    "    label = category_to_label[category] \n",
    "\n",
    "    # Looping through images in the current category\n",
    "    for dirpath, dirnames, filenames in os.walk(category_dir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(dirpath, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Resize the image \n",
    "                image = cv2.resize(image, target_size)\n",
    "                dataset.append(image)\n",
    "                labels.append(label)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c890ad8-fb2d-4b29-a117-405b7933213c",
   "metadata": {
    "id": "1c890ad8-fb2d-4b29-a117-405b7933213c"
   },
   "outputs": [],
   "source": [
    "# Converting dataset and labels to NumPy arrays\n",
    "dataset = np.array(dataset)\n",
    "labels = np.array(labels)\n",
    "labels = labels.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddc1885-d6e4-4157-bae9-0f3fe68f5dd3",
   "metadata": {
    "id": "4ddc1885-d6e4-4157-bae9-0f3fe68f5dd3"
   },
   "source": [
    "# Collecting information about dataset loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f661b32-3c24-4636-ab9c-76d598e49583",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f661b32-3c24-4636-ab9c-76d598e49583",
    "outputId": "e9478b6e-fd2a-4766-abc8-85a309b64aad"
   },
   "outputs": [],
   "source": [
    "print(len(dataset))\n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80cf4a7-d3af-4d62-b48e-81b736aaad78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f80cf4a7-d3af-4d62-b48e-81b736aaad78",
    "outputId": "ea4e7f68-48a0-4a2b-c48a-8fad52ca68a6"
   },
   "outputs": [],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816fcc13-1ee0-49f3-869f-51cd330646de",
   "metadata": {
    "id": "816fcc13-1ee0-49f3-869f-51cd330646de"
   },
   "outputs": [],
   "source": [
    "for idx, image_array in enumerate(dataset, start=1):\n",
    "    height, width, channels = image_array.shape\n",
    "    #print(f\"Image {idx} - Width: {width}, Height: {height}, Channels: {channels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7cddb1-afc0-4d2e-8134-cfd5cafdb5bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae7cddb1-afc0-4d2e-8134-cfd5cafdb5bb",
    "outputId": "a44741b8-a2b3-44d7-a2f3-da1c7c8fff5c"
   },
   "outputs": [],
   "source": [
    "# index for the image\n",
    "image_index = 1  \n",
    "normalized_image_array = dataset[image_index]\n",
    "\n",
    "# Display \n",
    "print(\"Image Shape:\", normalized_image_array.shape)\n",
    "print(\"Minimum Pixel Value:\", np.min(normalized_image_array))\n",
    "print(\"Maximum Pixel Value:\", np.max(normalized_image_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c15d4ca-ab79-41c8-9cb3-c567438860f6",
   "metadata": {
    "id": "3c15d4ca-ab79-41c8-9cb3-c567438860f6"
   },
   "source": [
    "# Preprocessing the image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b6fed1-50ee-414e-a35e-42e8c9ad6a22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 912
    },
    "id": "30b6fed1-50ee-414e-a35e-42e8c9ad6a22",
    "outputId": "fef0cf47-30f0-4cac-9f65-a08c498f3511"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_image(image_array, title):\n",
    "    # Displays the image with a title and hides axes\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image_array)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def preprocess_and_resize(image_array, target_size):\n",
    "    # Resizes the image to the given size\n",
    "    resized_image = cv2.resize(image_array, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Normalizes pixel values\n",
    "    normalized_image = resized_image / 255.0\n",
    "\n",
    "    # Sharpens the image using a filter\n",
    "    sharpening_filter = np.array([[-1, -1, -1],\n",
    "                                   [-1,  9, -1],\n",
    "                                   [-1, -1, -1]])\n",
    "    sharpened_image = cv2.filter2D(normalized_image, -1, sharpening_filter)\n",
    "\n",
    "    # Blends the sharpened and normalized images\n",
    "    final_image = 0.8 * normalized_image + 0.2 * sharpened_image\n",
    "\n",
    "    # Keeps pixel values within range\n",
    "    final_image = np.clip(final_image, 0, 1)\n",
    "\n",
    "    return final_image\n",
    "\n",
    "# Index of the image to display\n",
    "image_to_display_index = 1\n",
    "image_to_display = dataset[image_to_display_index]\n",
    "\n",
    "# Displays the original image\n",
    "display_image(image_to_display, \"Original Image\")\n",
    "\n",
    "# Desired size for all images\n",
    "target_size = (240, 140)\n",
    "\n",
    "# Preprocess and resize all images\n",
    "preprocessed_resized_images = [preprocess_and_resize(image_array, target_size) for image_array in dataset]\n",
    "\n",
    "# Displays the processed version of the chosen image\n",
    "display_image(preprocessed_resized_images[image_to_display_index], \"Preprocessed, Resized, and Sharpened Image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c530b664-8b2e-47e4-8dcc-8f180e892139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_image(image_array, title):\n",
    "    # Displays the image with a title and hides axes\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image_array, cmap='gray')  # Using grayscale for segmentation\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def preprocess_image(image_array, target_size):\n",
    "    # Resizes the image to the given size\n",
    "    resized_image = cv2.resize(image_array, target_size)\n",
    "\n",
    "    # Converts the image to grayscale\n",
    "    grayscale_image = cv2.cvtColor(resized_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Segments the image using Otsu's thresholding\n",
    "    _, segmented_image = cv2.threshold(grayscale_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Normalizes pixel values to the range [0, 1]\n",
    "    normalized_image = resized_image / 255.0\n",
    "\n",
    "    # Adjusts segmented image dimensions to match the normalized image\n",
    "    segmented_image = np.expand_dims(segmented_image, axis=-1)\n",
    "\n",
    "    # Blends the normalized and segmented images\n",
    "    final_image = 0.5 * normalized_image + 0.5 * segmented_image / 255.0\n",
    "\n",
    "    return final_image\n",
    "\n",
    "# Index of the image to display\n",
    "image_to_display_index = 10\n",
    "image_to_display = dataset[image_to_display_index]\n",
    "\n",
    "# Displays the original image\n",
    "display_image(image_to_display, \"Original Image\")\n",
    "\n",
    "# Sets the target size for all images\n",
    "target_size = (224, 147)\n",
    "\n",
    "# Preprocess and segment all images\n",
    "preprocessed_images = [preprocess_image(image_array, target_size) for image_array in dataset]\n",
    "\n",
    "# Displays the processed version of the selected image\n",
    "display_image(preprocessed_images[image_to_display_index], \"Preprocessed and Segmented Image\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bd53de-a087-40b7-8643-749199a247b0",
   "metadata": {
    "id": "53bd53de-a087-40b7-8643-749199a247b0"
   },
   "source": [
    "# Checking if image data is normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3694534c-cc15-45c9-8188-877745d67ffc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3694534c-cc15-45c9-8188-877745d67ffc",
    "outputId": "523dd791-b39f-4454-ec36-6165d10ea55c"
   },
   "outputs": [],
   "source": [
    "# Select the index of the image to examine\n",
    "image_index = 4  # Change this to the index of the image you want to analyze\n",
    "\n",
    "# Retrieve the normalized image array for the selected image\n",
    "normalized_image_array = preprocessed_images[image_index]\n",
    "\n",
    "# Uncomment this line if using preprocessed and sharpened images\n",
    "# normalized_image_array = preprocessed_and_sharpened_images[image_index]\n",
    "\n",
    "# Print details about the normalized image\n",
    "print(\"Image Shape:\", normalized_image_array.shape)\n",
    "print(\"Labels Shape:\", labels.shape)\n",
    "print(\"Minimum Pixel Value:\", np.min(normalized_image_array))\n",
    "print(\"Maximum Pixel Value:\", np.max(normalized_image_array))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc85b16-d3cc-456b-9172-6c515def5528",
   "metadata": {
    "id": "fdc85b16-d3cc-456b-9172-6c515def5528"
   },
   "source": [
    "# Splitting the dataset into training, testing, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd74b8-8165-46fb-a178-551f3bd095e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9cd74b8-8165-46fb-a178-551f3bd095e1",
    "outputId": "d358a77c-b4a8-4349-be70-058b100ccdfc"
   },
   "outputs": [],
   "source": [
    "# Here, we use an 80-10-10 split for train-test-validation respectively\n",
    "train_images, temp_images, train_labels, temp_labels = train_test_split(preprocessed_images, labels, test_size=0.2, random_state=42)\n",
    "test_images, val_images, test_labels, val_labels = train_test_split(temp_images, temp_labels, test_size=0.5, random_state=42)\n",
    "print(len(train_images), len(train_labels), len(val_images), len(val_labels), len(test_images), len(test_labels))\n",
    "\n",
    "# Assuming train_data and test_data are your training and test datasets\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "val_images = np.array(val_images)\n",
    "test_images = np.array(test_images)\n",
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(\"train Shape:\", train_images.shape)\n",
    "print(\"train labels Shape:\", train_labels.shape)\n",
    "print(\"val Shape:\", val_images.shape)\n",
    "print(\"val labels Shape:\", val_labels.shape)\n",
    "print(\"test Shape:\", test_images.shape)\n",
    "print(\"test labels Shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56fdc3e-3e3c-472f-b784-00cfca4094c2",
   "metadata": {
    "id": "e56fdc3e-3e3c-472f-b784-00cfca4094c2"
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dacf1a-d16f-4397-9b38-9c86c0c61c1a",
   "metadata": {
    "id": "a9dacf1a-d16f-4397-9b38-9c86c0c61c1a"
   },
   "source": [
    "# DenseNet-201 model with the ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb42a49-9e18-46a2-9f1c-96224bc55cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Use DenseNet-201 as the base model without its fully connected layers\n",
    "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # Adjust the number of classes as needed\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "adam = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Store evaluation results\n",
    "test_accuracy_DenseNet201_ADAM_01 = test_accuracy\n",
    "test_precision_DenseNet201_ADAM_01 = test_precision\n",
    "test_recall_DenseNet201_ADAM_01 = test_recall\n",
    "test_cohen_kappa_DenseNet201_ADAM_01 = test_cohen_kappa\n",
    "test_jaccard_index_DenseNet201_ADAM_01 = test_jaccard_index\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Save the accuracy plot\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_DenseNet201_ADAM_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_DenseNet201_ADAM_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64735150-dda6-4652-af90-5f3f1990786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load DenseNet-201 as the base model without its top layers\n",
    "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling for feature extraction\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # Number of classes in your dataset\n",
    "\n",
    "# Compile the model with the Adam optimizer\n",
    "adam = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model structure\n",
    "model.summary()\n",
    "\n",
    "# Train the model with training and validation data\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Save the metrics for this configuration\n",
    "test_accuracy_DenseNet201_ADAM_001 = test_accuracy\n",
    "test_precision_DenseNet201_ADAM_001 = test_precision\n",
    "test_recall_DenseNet201_ADAM_001 = test_recall\n",
    "test_cohen_kappa_DenseNet201_ADAM_001 = test_cohen_kappa\n",
    "test_jaccard_index_DenseNet201_ADAM_001 = test_jaccard_index\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot training and validation accuracy over epochs\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Save the accuracy plot to a directory\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_DenseNet201_ADAM_001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_DenseNet201_ADAM_001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afce3a4-b77c-4956-b83c-b3cb3326ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "test_accuracy_DenseNet201_ADAM_0001 = test_accuracy\n",
    "test_precision_DenseNet201_ADAM_0001 = test_precision\n",
    "test_recall_DenseNet201_ADAM_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_DenseNet201_ADAM_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_DenseNet201_ADAM_0001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_DenseNet201_ADAM_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_DenseNet201_ADAM_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16770c6-3ad1-4501-8bb2-bbd789e1404c",
   "metadata": {
    "id": "d16770c6-3ad1-4501-8bb2-bbd789e1404c"
   },
   "source": [
    "# DenseNet-201 model with the SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e39292b-ca44-4e36-bb0c-70622ea4aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.01)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_DenseNet201_SGD = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "test_accuracy_DenseNet201_SGD_01 = test_accuracy\n",
    "test_precision_DenseNet201_SGD_01 = test_precision\n",
    "test_recall_DenseNet201_SGD_01 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_DenseNet201_SGD_01 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_DenseNet201_SGD_01 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_DenseNet201_SGD_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_DenseNet201_SGD_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35571228-f522-416d-bf6e-42030caa0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.001)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_DenseNet201_SGD = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "test_accuracy_DenseNet201_SGD_001 = test_accuracy\n",
    "test_precision_DenseNet201_SGD_001 = test_precision\n",
    "test_recall_DenseNet201_SGD_001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_DenseNet201_SGD_001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_DenseNet201_SGD_001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_DenseNet201_SGD_001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_DenseNet201_SGD_001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9d3e87-345a-4568-a3e7-4822883bb069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.0001)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_DenseNet201_SGD = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "test_accuracy_DenseNet201_SGD_0001 = test_accuracy\n",
    "test_precision_DenseNet201_SGD_0001 = test_precision\n",
    "test_recall_DenseNet201_SGD_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_DenseNet201_SGD_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_DenseNet201_SGD_0001 = test_jaccard_index\n",
    "\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_DenseNet201_SGD_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_DenseNet201_SGD_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af70e03d-28a8-4a1a-b7a5-aac7fb04fc8d",
   "metadata": {
    "id": "af70e03d-28a8-4a1a-b7a5-aac7fb04fc8d"
   },
   "source": [
    "# DenseNet-201 model with the RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8f75d8-05f2-47ea-8422-ab921fcc217f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "0a8f75d8-05f2-47ea-8422-ab921fcc217f",
    "outputId": "d4e2aefb-6850-4825-d4bc-a3d0f218c46d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.01)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_DenseNet201_RMSprop_01 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "test_precision_DenseNet201_RMSprop_01 = test_precision\n",
    "test_recall_DenseNet201_RMSprop_01 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_DenseNet201_RMSprop_01 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_DenseNet201_RMSprop_01 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_DenseNet201_RMSprop_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_DenseNet201_RMSprop_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8c544-4119-4ecc-ac26-4575b47f8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_DenseNet201_RMSprop_001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "test_precision_DenseNet201_RMSprop_001 = test_precision\n",
    "test_recall_DenseNet201_RMSprop_001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_DenseNet201_RMSprop_001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_DenseNet201_RMSprop_001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_DenseNet201_RMSprop.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_DenseNet201_RMSprop.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8f786-d5c1-47ab-b707-f39e366be035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.0001)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_DenseNet201_RMSprop_0001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "test_precision_DenseNet201_RMSprop_0001 = test_precision\n",
    "test_recall_DenseNet201_RMSprop_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_DenseNet201_RMSprop_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_DenseNet201_RMSprop_0001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_DenseNet201_RMSprop_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_DenseNet201_RMSprop_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ece533-d0cf-40f5-9dbd-998aab19c196",
   "metadata": {},
   "source": [
    "# COMPARATIVE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba4d32-e914-4597-ac13-7472a6581dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# List of optimizers\n",
    "optimizers = ['Adam', 'SGD', 'RMSprop']\n",
    "\n",
    "# List of learning rates\n",
    "learning_rates = ['LR: 0.01', 'LR: 0.001', 'LR: 0.0001']\n",
    "\n",
    "# List of corresponding accuracy values\n",
    "accuracies = [\n",
    "    [test_accuracy_DenseNet201_ADAM_01, test_accuracy_DenseNet201_ADAM_001, test_accuracy_DenseNet201_ADAM_0001],\n",
    "    [test_accuracy_DenseNet201_SGD_01, test_accuracy_DenseNet201_SGD_001, test_accuracy_DenseNet201_SGD_0001],\n",
    "    [test_accuracy_DenseNet201_RMSprop_01, test_accuracy_DenseNet201_RMSprop_001, test_accuracy_DenseNet201_RMSprop_0001]\n",
    "]\n",
    "\n",
    "# Set the width of each bar\n",
    "bar_width = 0.9\n",
    "\n",
    "# Set the distance between bars for different optimizers\n",
    "distance_between_optimizers = 0.6\n",
    "\n",
    "# Set the distance between optimizer names on the x-axis\n",
    "distance_between_names = 4\n",
    "\n",
    "# Define unique colors for each learning rate\n",
    "lr_colors = {'LR: 0.01': 'skyblue', 'LR: 0.001': 'brown', 'LR: 0.0001': 'lightgreen'}\n",
    "\n",
    "# Plot grouped bar graph\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot bars for each optimizer\n",
    "for i, optimizer in enumerate(optimizers):\n",
    "    positions = np.arange(len(learning_rates)) + i * (len(learning_rates) * (bar_width + distance_between_optimizers))\n",
    "    for j, lr in enumerate(learning_rates):\n",
    "        color = lr_colors[lr]\n",
    "        ax.bar(positions[j], accuracies[i][j], bar_width, label=f'{lr}', color=color)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Optimizers')\n",
    "ax.set_ylabel('Test Accuracy')\n",
    "ax.set_title('Test Accuracy vs Optimizers')\n",
    "ax.set_xticks(np.arange(len(optimizers)) * distance_between_names + (len(learning_rates) - 1) * (bar_width + distance_between_optimizers) / 2)\n",
    "ax.set_xticklabels(optimizers)\n",
    "\n",
    "# Add legend with adjusted position and ordered values\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "unique_labels = list(set(labels))\n",
    "# Order values in the legend\n",
    "ordered_values = ['0.01', '0.001', '0.0001']\n",
    "# Create a dictionary to map old labels to new labels\n",
    "label_mapping = {f'LR: {value}': f'LR: {value}' for value in ordered_values}\n",
    "new_labels = [label_mapping[label] for label in labels]\n",
    "# Plot the legend\n",
    "ax.legend(handles[:len(learning_rates)], new_labels, title='Learning Rate', bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "# Save the plot\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "plot_filename = os.path.join(output_directory, 'comparative_analysis_DenseNet201.png')\n",
    "plt.savefig(plot_filename, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959b27e8-5ef3-4595-bb7c-532bb71a36f6",
   "metadata": {
    "id": "959b27e8-5ef3-4595-bb7c-532bb71a36f6"
   },
   "source": [
    "# InceptionV3 with Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78121973-f07b-4f8f-806d-11d836e18195",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "78121973-f07b-4f8f-806d-11d836e18195",
    "outputId": "678e5e8d-4fae-4654-9eb2-e1742a39d1ac"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "Adam = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_InceptionV3_ADAM_01 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_InceptionV3_ADAM_01 = test_precision\n",
    "test_recall_InceptionV3_ADAM_01 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_InceptionV3_ADAM_01 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_InceptionV3_ADAM_01 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_InceptionV3_ADAM_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_InceptionV3_ADAM_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2dbe30-40c1-4b84-9bfc-6a0892188408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "Adam = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_InceptionV3_ADAM_001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_InceptionV3_ADAM_001 = test_precision\n",
    "test_recall_InceptionV3_ADAM_001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_InceptionV3_ADAM_001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_InceptionV3_ADAM_001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_InceptionV3_ADAM_001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_InceptionV3_ADAM_001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368efcfc-f41e-4a8e-b984-1ea5b0c85921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "Adam = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_InceptionV3_ADAM_0001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_InceptionV3_ADAM_0001 = test_precision\n",
    "test_recall_InceptionV3_ADAM_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_InceptionV3_ADAM_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_InceptionV3_ADAM_0001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_InceptionV3_ADAM_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_InceptionV3_ADAM_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd433cd-7914-4bd9-91ae-22cdc40b7c04",
   "metadata": {
    "id": "efd433cd-7914-4bd9-91ae-22cdc40b7c04"
   },
   "source": [
    "# InceptionV3 with SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed922a-058b-4f26-9ac3-2c68d4e649b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "45ed922a-058b-4f26-9ac3-2c68d4e649b3",
    "outputId": "c2b76383-4480-464a-fe32-a5f0d1d69ef0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop \n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.01)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_InceptionV3_SGD_01 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_InceptionV3_SGD_01 = test_precision\n",
    "test_recall_InceptionV3_SGD_01 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_InceptionV3_SGD_01 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_InceptionV3_SGD_01 = test_jaccard_index\n",
    "\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_InceptionV3_SGD_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_InceptionV3_SGD_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669cbb19-a727-4136-aaff-12b8526ff071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop \n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.001)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_InceptionV3_SGD_001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_InceptionV3_SGD_001 = test_precision\n",
    "test_recall_InceptionV3_SGD_001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_InceptionV3_SGD_001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_InceptionV3_SGD_001 = test_jaccard_index\n",
    "\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_InceptionV3_SGD_001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_InceptionV3_SGD_001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56e947-23e2-433e-9df4-93152b0fe466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop \n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.0001)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_InceptionV3_SGD_0001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_InceptionV3_SGD_0001 = test_precision\n",
    "test_recall_InceptionV3_SGD_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_InceptionV3_SGD_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_InceptionV3_SGD_0001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_InceptionV3_SGD_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_InceptionV3_SGD_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed7a6a-2d39-49b0-9fd9-394e3fbefb54",
   "metadata": {
    "id": "35ed7a6a-2d39-49b0-9fd9-394e3fbefb54"
   },
   "source": [
    "# InceptionV3 with RMSprop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662cd67-4cef-4238-8973-4b1ce9fa80a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "c662cd67-4cef-4238-8973-4b1ce9fa80a7",
    "outputId": "363d5310-786d-4691-8c54-66d1a2448ab9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.01)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_InceptionV3_RMSprop_01 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_InceptionV3_RMSprop_01 = test_precision\n",
    "test_recall_InceptionV3_RMSprop_01 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_InceptionV3_RMSprop_01 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_InceptionV3_RMSprop_01 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_InceptionV3_RMSprop_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_InceptionV3_RMSprop_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7f4dd-4048-45ca-bf72-063f560addc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_InceptionV3_RMSprop_001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_InceptionV3_RMSprop_001 = test_precision\n",
    "test_recall_InceptionV3_RMSprop_001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_InceptionV3_RMSprop_001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_InceptionV3_RMSprop_001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_InceptionV3_RMSprop_001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_InceptionV3_RMSprop_001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9330651-5ba0-4df6-b6db-792ce7431a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.0001)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_InceptionV3_RMSprop_0001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_InceptionV3_RMSprop_0001 = test_precision\n",
    "test_recall_InceptionV3_RMSprop_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_InceptionV3_RMSprop_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_InceptionV3_RMSprop_0001 = test_jaccard_index\n",
    "\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_InceptionV3_RMSprop_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_InceptionV3_RMSprop_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f0c9d-68f6-4a96-9a71-6ed1ae5196e5",
   "metadata": {},
   "source": [
    "# COMPARATIVE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1a966-e04b-4c18-b5b5-12aad29e4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# List of optimizers\n",
    "optimizers = ['Adam', 'SGD', 'RMSprop']\n",
    "\n",
    "# List of learning rates\n",
    "learning_rates = ['LR: 0.01', 'LR: 0.001', 'LR: 0.0001']\n",
    "\n",
    "# List of corresponding accuracy values\n",
    "accuracies = [\n",
    "    [test_accuracy_InceptionV3_ADAM_01, test_accuracy_InceptionV3_ADAM_001, test_accuracy_InceptionV3_ADAM_0001],\n",
    "    [test_accuracy_InceptionV3_SGD_01, test_accuracy_InceptionV3_SGD_001, test_accuracy_InceptionV3_SGD_0001],\n",
    "    [test_accuracy_InceptionV3_RMSprop_01, test_accuracy_InceptionV3_RMSprop_001, test_accuracy_InceptionV3_RMSprop_0001]\n",
    "]\n",
    "\n",
    "# Set the width of each bar\n",
    "bar_width = 0.9\n",
    "\n",
    "# Set the distance between bars for different optimizers\n",
    "distance_between_optimizers = 0.6\n",
    "\n",
    "# Set the distance between optimizer names on the x-axis\n",
    "distance_between_names = 4\n",
    "\n",
    "# Define unique colors for each learning rate\n",
    "lr_colors = {'LR: 0.01': 'skyblue', 'LR: 0.001': 'brown', 'LR: 0.0001': 'lightgreen'}\n",
    "\n",
    "# Plot grouped bar graph\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot bars for each optimizer\n",
    "for i, optimizer in enumerate(optimizers):\n",
    "    positions = np.arange(len(learning_rates)) + i * (len(learning_rates) * (bar_width + distance_between_optimizers))\n",
    "    for j, lr in enumerate(learning_rates):\n",
    "        color = lr_colors[lr]\n",
    "        ax.bar(positions[j], accuracies[i][j], bar_width, label=f'{lr}', color=color)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Optimizers')\n",
    "ax.set_ylabel('Test Accuracy')\n",
    "ax.set_title('Test Accuracy vs Optimizers')\n",
    "ax.set_xticks(np.arange(len(optimizers)) * distance_between_names + (len(learning_rates) - 1) * (bar_width + distance_between_optimizers) / 2)\n",
    "ax.set_xticklabels(optimizers)\n",
    "\n",
    "# Add legend with adjusted position and ordered values\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "unique_labels = list(set(labels))\n",
    "# Order values in the legend\n",
    "ordered_values = ['0.01', '0.001', '0.0001']\n",
    "# Create a dictionary to map old labels to new labels\n",
    "label_mapping = {f'LR: {value}': f'LR: {value}' for value in ordered_values}\n",
    "new_labels = [label_mapping[label] for label in labels]\n",
    "# Plot the legend\n",
    "ax.legend(handles[:len(learning_rates)], new_labels, title='Learning Rate', bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "# Save the plot\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "plot_filename = os.path.join(output_directory, 'comparative_analysis_InceptionV3.png')\n",
    "plt.savefig(plot_filename, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4e7eaa-0506-4d5a-8eec-c8ed9d245e19",
   "metadata": {
    "id": "cc4e7eaa-0506-4d5a-8eec-c8ed9d245e19"
   },
   "source": [
    "# MobileNetV2 with ADAM optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be60411a-4171-446e-b08b-195ec4e2e0f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 891
    },
    "id": "be60411a-4171-446e-b08b-195ec4e2e0f9",
    "outputId": "12331002-9c89-44a7-fec5-99710d40a8db"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "Adam = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_MobileNetV2_ADAM_01 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_MobileNetV2_ADAM_01 = test_precision\n",
    "test_recall_MobileNetV2_ADAM_01 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_MobileNetV2_ADAM_01 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_MobileNetV2_ADAM_01 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_MobileNetV2_ADAM_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_MobileNetV2_ADAM_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37464dd-4073-4458-bd2b-73ed0cfc43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "Adam = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_MobileNetV2_ADAM_001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_MobileNetV2_ADAM_001 = test_precision\n",
    "test_recall_MobileNetV2_ADAM_001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_MobileNetV2_ADAM_001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_MobileNetV2_ADAM_001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_MobileNetV2_ADAM_001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_MobileNetV2_ADAM_001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0cc87e-1ad7-404d-9483-5f1dbf75ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "Adam = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_MobileNetV2_ADAM_0001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_MobileNetV2_ADAM_0001 = test_precision\n",
    "test_recall_MobileNetV2_ADAM_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_MobileNetV2_ADAM_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_MobileNetV2_ADAM_0001 = test_jaccard_index\n",
    "\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_MobileNetV2_ADAM_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_MobileNetV2_ADAM_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1222100-b395-481c-8d79-1d87eb9f01fc",
   "metadata": {
    "id": "d1222100-b395-481c-8d79-1d87eb9f01fc"
   },
   "source": [
    "# MobileNetV2 with SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95489e0a-e44e-47e8-be44-fbf8828d9b2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 891
    },
    "id": "95489e0a-e44e-47e8-be44-fbf8828d9b2d",
    "outputId": "8b18b67e-e4b2-4bce-eb4d-3bf9326011fc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.01)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_MobileNetV2_SGD_01 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_MobileNetV2_SGD_01 = test_precision\n",
    "test_recall_MobileNetV2_SGD_01 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_MobileNetV2_SGD_01 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_MobileNetV2_SGD_01 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_MobileNetV2_SGD_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_MobileNetV2_SGD_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d82bc26-dae6-4e5b-99a1-f989b21038cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.001)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_MobileNetV2_SGD_001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_MobileNetV2_SGD_001 = test_precision\n",
    "test_recall_MobileNetV2_SGD_001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_MobileNetV2_SGD_001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_MobileNetV2_SGD_001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_MobileNetV2_SGD_001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_MobileNetV2_SGD_001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caedeeb-5961-450c-bcb8-c0e1b78271c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.0001)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_MobileNetV2_SGD_0001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_MobileNetV2_SGD_0001 = test_precision\n",
    "test_recall_MobileNetV2_SGD_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_MobileNetV2_SGD_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_MobileNetV2_SGD_0001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_MobileNetV2_SGD_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_MobileNetV2_SGD_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a905e-7a3a-4301-a8fe-452667ac6e4e",
   "metadata": {
    "id": "644a905e-7a3a-4301-a8fe-452667ac6e4e"
   },
   "source": [
    "# MobileNetV2 with RMSprop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824f4489-2e4c-4933-b7ac-825e3668e526",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 891
    },
    "id": "824f4489-2e4c-4933-b7ac-825e3668e526",
    "outputId": "3c92f823-4542-4610-bd6e-829f3120eb74"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.01)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_MobileNetV2_RMSprop_01 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_MobileNetV2_RMSprop_01 = test_precision\n",
    "test_recall_MobileNetV2_RMSprop_01 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_MobileNetV2_RMSprop_01 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_MobileNetV2_RMSprop_01 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_MobileNetV2_RMSprop_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_MobileNetV2_RMSprop_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0de8aad-7394-41aa-a76e-3a273f3e0f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_MobileNetV2_RMSprop_001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_MobileNetV2_RMSprop_001 = test_precision\n",
    "test_recall_MobileNetV2_RMSprop_001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_MobileNetV2_RMSprop_001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_MobileNetV2_RMSprop_001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_MobileNetV2_RMSprop_001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_MobileNetV2_RMSprop_001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b4a3d-fb28-47b4-a877-c3cd610606f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.0001)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_MobileNetV2_RMSprop_0001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_MobileNetV2_RMSprop_0001 = test_precision\n",
    "test_recall_MobileNetV2_RMSprop_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_MobileNetV2_RMSprop_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_MobileNetV2_RMSprop_0001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_MobileNetV2_RMSprop_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_MobileNetV2_RMSprop_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ddf105-46ed-4ba7-ac1d-39b5d18f812a",
   "metadata": {},
   "source": [
    "# COMPARATIVE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4e77c-12d8-4f89-a9c5-1cdc520a52ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# List of optimizers\n",
    "optimizers = ['Adam', 'SGD', 'RMSprop']\n",
    "\n",
    "# List of learning rates\n",
    "learning_rates = ['LR: 0.01', 'LR: 0.001', 'LR: 0.0001']\n",
    "\n",
    "# List of corresponding accuracy values\n",
    "accuracies = [\n",
    "    [test_accuracy_MobileNetV2_ADAM_01, test_accuracy_MobileNetV2_ADAM_001, test_accuracy_MobileNetV2_ADAM_0001],\n",
    "    [test_accuracy_MobileNetV2_SGD_01, test_accuracy_MobileNetV2_SGD_001, test_accuracy_MobileNetV2_SGD_0001],\n",
    "    [test_accuracy_MobileNetV2_RMSprop_01, test_accuracy_MobileNetV2_RMSprop_001, test_accuracy_MobileNetV2_RMSprop_0001]\n",
    "]\n",
    "\n",
    "# Set the width of each bar\n",
    "bar_width = 0.9\n",
    "\n",
    "# Set the distance between bars for different optimizers\n",
    "distance_between_optimizers = 0.6\n",
    "\n",
    "# Set the distance between optimizer names on the x-axis\n",
    "distance_between_names = 4\n",
    "\n",
    "# Define unique colors for each learning rate\n",
    "lr_colors = {'LR: 0.01': 'skyblue', 'LR: 0.001': 'brown', 'LR: 0.0001': 'lightgreen'}\n",
    "\n",
    "# Plot grouped bar graph\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot bars for each optimizer\n",
    "for i, optimizer in enumerate(optimizers):\n",
    "    positions = np.arange(len(learning_rates)) + i * (len(learning_rates) * (bar_width + distance_between_optimizers))\n",
    "    for j, lr in enumerate(learning_rates):\n",
    "        color = lr_colors[lr]\n",
    "        ax.bar(positions[j], accuracies[i][j], bar_width, label=f'{lr}', color=color)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Optimizers')\n",
    "ax.set_ylabel('Test Accuracy')\n",
    "ax.set_title('Test Accuracy vs Optimizers')\n",
    "ax.set_xticks(np.arange(len(optimizers)) * distance_between_names + (len(learning_rates) - 1) * (bar_width + distance_between_optimizers) / 2)\n",
    "ax.set_xticklabels(optimizers)\n",
    "\n",
    "# Add legend with adjusted position and ordered values\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "unique_labels = list(set(labels))\n",
    "# Order values in the legend\n",
    "ordered_values = ['0.01', '0.001', '0.0001']\n",
    "# Create a dictionary to map old labels to new labels\n",
    "label_mapping = {f'LR: {value}': f'LR: {value}' for value in ordered_values}\n",
    "new_labels = [label_mapping[label] for label in labels]\n",
    "# Plot the legend\n",
    "ax.legend(handles[:len(learning_rates)], new_labels, title='Learning Rate', bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "# Save the plot\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "plot_filename = os.path.join(output_directory, 'comparative_analysis_MobileNetV2.png')\n",
    "plt.savefig(plot_filename, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64472b4e-e1f5-483b-adeb-3d46ac911f40",
   "metadata": {
    "id": "64472b4e-e1f5-483b-adeb-3d46ac911f40"
   },
   "source": [
    "# ResNet50 with Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94706a2b-4756-4a7d-b0be-35ef213ce36b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "94706a2b-4756-4a7d-b0be-35ef213ce36b",
    "outputId": "68988b0f-da80-4708-e41e-4b93cb5c1ddf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "Adam = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_ResNet50_ADAM_01 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_ResNet50_ADAM_01 = test_precision\n",
    "test_recall_ResNet50_ADAM_01 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_ResNet50_ADAM_01 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_ResNet50_ADAM_01 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_ResNet50_ADAM_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_ResNet50_ADAM_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d65da-7526-49ab-9aa3-46ce81f34773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "Adam = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_ResNet50_ADAM_001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_ResNet50_ADAM_001 = test_precision\n",
    "test_recall_ResNet50_ADAM_001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_ResNet50_ADAM_001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_ResNet50_ADAM_001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_ResNet50_ADAM_001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_ResNet50_ADAM_001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eca39e1-2494-49ec-a6bc-181348270936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "Adam = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_ResNet50_ADAM_0001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_ResNet50_ADAM_0001 = test_precision\n",
    "test_recall_ResNet50_ADAM_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_ResNet50_ADAM_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_ResNet50_ADAM_0001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_ResNet50_ADAM_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_ResNet50_ADAM_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6dd93-f147-49b9-ba7b-0671ed6b56f0",
   "metadata": {
    "id": "3cd6dd93-f147-49b9-ba7b-0671ed6b56f0"
   },
   "source": [
    "# ResNet50 with SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b09cf4-7922-4cf4-bacc-a32de80b60f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "40b09cf4-7922-4cf4-bacc-a32de80b60f8",
    "outputId": "fa6c7170-4203-4b0e-9abb-93a445e6733d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.01)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_ResNet50_SGD_01 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_ResNet50_SGD_01 = test_precision\n",
    "test_recall_ResNet50_SGD_01 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_ResNet50_SGD_01 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_ResNet50_SGD_01 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_ResNet50_SGD_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_ResNet50_SGD_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a8725b-a78b-4d78-aa98-e2c5d7bbb4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.001)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_ResNet50_SGD_001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_ResNet50_SGD_001 = test_precision\n",
    "test_recall_ResNet50_SGD_001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_ResNet50_SGD_001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_ResNet50_SGD_001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_ResNet50_SGD_001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_ResNet50_SGD_001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8308c-f394-41e3-b32e-ddbef7a0ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.0001)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_ResNet50_SGD_0001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_ResNet50_SGD_0001 = test_precision\n",
    "test_recall_ResNet50_SGD_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_ResNet50_SGD_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_ResNet50_SGD_0001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_ResNet50_SGD_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_ResNet50_SGD_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e68fc98-c4fd-47ca-9925-04b2c45b2b02",
   "metadata": {
    "id": "8e68fc98-c4fd-47ca-9925-04b2c45b2b02"
   },
   "source": [
    "# ResNet50 with RMSprop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc01fd68-b7de-4ced-b5a0-b62ccac258da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "fc01fd68-b7de-4ced-b5a0-b62ccac258da",
    "outputId": "c5e515ac-c59d-4d63-965e-6586fa69abf0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.01)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_ResNet50_RMSprop_01 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_ResNet50_RMSprop_01 = test_precision\n",
    "test_recall_ResNet50_RMSprop_01 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_ResNet50_RMSprop_01 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_ResNet50_RMSprop_01 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_ResNet50_RMSprop_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_ResNet50_RMSprop_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeaed87-2911-460b-a9c5-dfe91aab4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_ResNet50_RMSprop_001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_ResNet50_RMSprop_001 = test_precision\n",
    "test_recall_ResNet50_RMSprop_001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_ResNet50_RMSprop_001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_ResNet50_RMSprop_001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_ResNet50_RMSprop_001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_ResNet50_RMSprop_001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af5ac8-2742-4b32-9c91-5b00d596d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.0001)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_ResNet50_RMSprop_0001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_ResNet50_RMSprop_0001 = test_precision\n",
    "test_recall_ResNet50_RMSprop_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_ResNet50_RMSprop_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_ResNet50_RMSprop_0001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_ResNet50_RMSprop_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_ResNet50_RMSprop_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac19d38-b29e-4ece-ac98-abdf6b65d79a",
   "metadata": {},
   "source": [
    "# COMPARATIVE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00b96b-50ae-4197-860a-a0bc4b929e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# List of optimizers\n",
    "optimizers = ['Adam', 'SGD', 'RMSprop']\n",
    "\n",
    "# List of learning rates\n",
    "learning_rates = ['LR: 0.01', 'LR: 0.001', 'LR: 0.0001']\n",
    "\n",
    "# List of corresponding accuracy values\n",
    "accuracies = [\n",
    "    [test_accuracy_ResNet50_ADAM_01, test_accuracy_ResNet50_ADAM_001, test_accuracy_ResNet50_ADAM_0001],\n",
    "    [test_accuracy_ResNet50_SGD_01, test_accuracy_ResNet50_SGD_001, test_accuracy_ResNet50_SGD_0001],\n",
    "    [test_accuracy_ResNet50_RMSprop_01, test_accuracy_ResNet50_RMSprop_001, test_accuracy_ResNet50_RMSprop_0001]\n",
    "]\n",
    "\n",
    "# Set the width of each bar\n",
    "bar_width = 0.9\n",
    "\n",
    "# Set the distance between bars for different optimizers\n",
    "distance_between_optimizers = 0.6\n",
    "\n",
    "# Set the distance between optimizer names on the x-axis\n",
    "distance_between_names = 4\n",
    "\n",
    "# Define unique colors for each learning rate\n",
    "lr_colors = {'LR: 0.01': 'skyblue', 'LR: 0.001': 'brown', 'LR: 0.0001': 'lightgreen'}\n",
    "\n",
    "# Plot grouped bar graph\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot bars for each optimizer\n",
    "for i, optimizer in enumerate(optimizers):\n",
    "    positions = np.arange(len(learning_rates)) + i * (len(learning_rates) * (bar_width + distance_between_optimizers))\n",
    "    for j, lr in enumerate(learning_rates):\n",
    "        color = lr_colors[lr]\n",
    "        ax.bar(positions[j], accuracies[i][j], bar_width, label=f'{lr}', color=color)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Optimizers')\n",
    "ax.set_ylabel('Test Accuracy')\n",
    "ax.set_title('Test Accuracy vs Optimizers')\n",
    "ax.set_xticks(np.arange(len(optimizers)) * distance_between_names + (len(learning_rates) - 1) * (bar_width + distance_between_optimizers) / 2)\n",
    "ax.set_xticklabels(optimizers)\n",
    "\n",
    "# Add legend with adjusted position and ordered values\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "unique_labels = list(set(labels))\n",
    "# Order values in the legend\n",
    "ordered_values = ['0.01', '0.001', '0.0001']\n",
    "# Create a dictionary to map old labels to new labels\n",
    "label_mapping = {f'LR: {value}': f'LR: {value}' for value in ordered_values}\n",
    "new_labels = [label_mapping[label] for label in labels]\n",
    "# Plot the legend\n",
    "ax.legend(handles[:len(learning_rates)], new_labels, title='Learning Rate', bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "# Save the plot\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "plot_filename = os.path.join(output_directory, 'comparative_analysis_ResNet50.png')\n",
    "plt.savefig(plot_filename, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b763bc-4471-40ef-9050-d62cea8c6b22",
   "metadata": {
    "id": "f6b763bc-4471-40ef-9050-d62cea8c6b22"
   },
   "source": [
    "# VGG19 with Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc872fd-7b29-480e-acf9-042d6fab57b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "afc872fd-7b29-480e-acf9-042d6fab57b9",
    "outputId": "9e361bc7-62ea-4a88-a6e1-88c629839faa"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with optimizer and appropriate loss function\n",
    "Adam = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_VGG19_ADAM_01 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_VGG19_ADAM_01 = test_precision\n",
    "test_recall_VGG19_ADAM_01 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_VGG19_ADAM_01 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_VGG19_ADAM_01 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_VGG19_ADAM_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_VGG19_ADAM_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb47f1f-7fd9-4ba6-88b0-d98015403bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "Adam = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_VGG19_ADAM_001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_VGG19_ADAM_001 = test_precision\n",
    "test_recall_VGG19_ADAM_001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_VGG19_ADAM_001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_VGG19_ADAM_001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_VGG19_ADAM_001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_VGG19_ADAM_001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa9e3de-0e7e-454a-a9e8-0acbc0f138b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "Adam = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_VGG19_ADAM_0001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_VGG19_ADAM_0001 = test_precision\n",
    "test_recall_VGG19_ADAM_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_VGG19_ADAM_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_VGG19_ADAM_0001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_VGG19_ADAM_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_VGG19_ADAM_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41e049-ac63-4732-8e3d-56f1ae2f8b50",
   "metadata": {
    "id": "2e41e049-ac63-4732-8e3d-56f1ae2f8b50"
   },
   "source": [
    "# VGG19 with SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfee47d-0d62-4533-a73f-ccfdea725393",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "1dfee47d-0d62-4533-a73f-ccfdea725393",
    "outputId": "f65bc657-4396-4107-a0bb-3302b8083ed6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.01)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_VGG19_SGD_01 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_VGG19_SGD_01 = test_precision\n",
    "test_recall_VGG19_SGD_01 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_VGG19_SGD_01 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_VGG19_SGD_01 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_VGG19_SGD_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_VGG19_SGD_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef5401-f500-4483-a240-d0a603a44357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.001)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_VGG19_SGD_001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_VGG19_SGD_001 = test_precision\n",
    "test_recall_VGG19_SGD_001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_VGG19_SGD_001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_VGG19_SGD_001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_VGG19_SGD_001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_VGG19_SGD_001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf19b60-a591-4b48-9a74-e41873606e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with optimizer and appropriate loss function\n",
    "SGD = SGD(learning_rate=0.0001)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_VGG19_SGD_0001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_VGG19_SGD_0001 = test_precision\n",
    "test_recall_VGG19_SGD_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_VGG19_SGD_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_VGG19_SGD_0001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_VGG19_SGD_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_VGG19_SGD_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b6ddfb-e7de-482c-a764-c534f08dc12b",
   "metadata": {
    "id": "c4b6ddfb-e7de-482c-a764-c534f08dc12b"
   },
   "source": [
    "# VGG19 with RMSprop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8578085-43a4-4b5a-864a-de5bdedf6368",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "b8578085-43a4-4b5a-864a-de5bdedf6368",
    "outputId": "34faee7b-fa88-4c98-9d22-98082e6bce00"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with Adam optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.01)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_VGG19_RMSprop_01 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_VGG19_RMSprop_01 = test_precision\n",
    "test_recall_VGG19_RMSprop_01 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_VGG19_RMSprop_01 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_VGG19_RMSprop_01 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_VGG19_RMSprop_01.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_VGG19_RMSprop_01.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f68fe7-c40d-4b33-8853-1be133c7dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_VGG19_RMSprop_001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_VGG19_RMSprop_001 = test_precision\n",
    "test_recall_VGG19_RMSprop_001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_VGG19_RMSprop_001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_VGG19_RMSprop_001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_VGG19_RMSprop_001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_VGG19_RMSprop_001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26baffaa-faa4-4472-a785-e2fc94fcf4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201, InceptionV3, MobileNetV2, ResNet50, VGG19\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Load the pre-trained DenseNet-201 model without the top (fully connected) layers\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(147, 224, 3))\n",
    "model.add(base_model)\n",
    "\n",
    "# Add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add custom top layers for classification\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 'num_classes' is the number of classes in your dataset\n",
    "\n",
    "# Compile the model with optimizer and appropriate loss function\n",
    "RMSprop = RMSprop(learning_rate=0.0001)\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = np.argmax(model.predict(test_images), axis=-1)\n",
    "#test_labels = np.argmax(test_labels, axis=-1)  # Only needed if one-hot encoded labels are used\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_accuracy_VGG19_RMSprop_0001 = test_accuracy\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "test_precision_VGG19_RMSprop_0001 = test_precision\n",
    "test_recall_VGG19_RMSprop_0001 = test_recall\n",
    "test_cohen_kappa = cohen_kappa_score(test_labels, test_predictions)\n",
    "test_cohen_kappa_VGG19_RMSprop_0001 = test_cohen_kappa\n",
    "test_jaccard_index = jaccard_score(test_labels, test_predictions, average='weighted')\n",
    "test_jaccard_index_VGG19_RMSprop_0001 = test_jaccard_index\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "print(\"Cohen's Kappa:\", test_cohen_kappa)\n",
    "print(\"Jaccard Index:\", test_jaccard_index)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "\n",
    "# Create a directory named 'results'\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save the plot inside the 'results' directory\n",
    "plot_filename = os.path.join(output_directory, 'accuracy_plot_VGG19_RMSprop_0001.png')\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the confusion matrix plot inside the 'results' directory\n",
    "confusion_matrix_filename = os.path.join(output_directory, 'confusion_matrix_VGG19_RMSprop_0001.png')\n",
    "plt.savefig(confusion_matrix_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95da1169-e2d3-42cf-b04d-8c0729075fe7",
   "metadata": {},
   "source": [
    "# COMPARATIVE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf5b98d-4633-497d-8f71-7159d60e9cd1",
   "metadata": {
    "id": "dbf5b98d-4633-497d-8f71-7159d60e9cd1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# List of optimizers\n",
    "optimizers = ['Adam', 'SGD', 'RMSprop']\n",
    "\n",
    "# List of learning rates\n",
    "learning_rates = ['LR: 0.01', 'LR: 0.001', 'LR: 0.0001']\n",
    "\n",
    "# List of corresponding accuracy values\n",
    "accuracies = [\n",
    "    [test_accuracy_VGG19_ADAM_01, test_accuracy_VGG19_ADAM_001, test_accuracy_VGG19_ADAM_0001],\n",
    "    [test_accuracy_VGG19_SGD_01, test_accuracy_VGG19_SGD_001, test_accuracy_VGG19_SGD_0001],\n",
    "    [test_accuracy_VGG19_RMSprop_01, test_accuracy_VGG19_RMSprop_001, test_accuracy_VGG19_RMSprop_0001]\n",
    "]\n",
    "\n",
    "# Set the width of each bar\n",
    "bar_width = 0.9\n",
    "\n",
    "# Set the distance between bars for different optimizers\n",
    "distance_between_optimizers = 0.6\n",
    "\n",
    "# Set the distance between optimizer names on the x-axis\n",
    "distance_between_names = 4\n",
    "\n",
    "# Define unique colors for each learning rate\n",
    "lr_colors = {'LR: 0.01': 'skyblue', 'LR: 0.001': 'brown', 'LR: 0.0001': 'lightgreen'}\n",
    "\n",
    "# Plot grouped bar graph\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot bars for each optimizer\n",
    "for i, optimizer in enumerate(optimizers):\n",
    "    positions = np.arange(len(learning_rates)) + i * (len(learning_rates) * (bar_width + distance_between_optimizers))\n",
    "    for j, lr in enumerate(learning_rates):\n",
    "        color = lr_colors[lr]\n",
    "        ax.bar(positions[j], accuracies[i][j], bar_width, label=f'{lr}', color=color)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Optimizers')\n",
    "ax.set_ylabel('Test Accuracy')\n",
    "ax.set_title('Test Accuracy vs Optimizers')\n",
    "ax.set_xticks(np.arange(len(optimizers)) * distance_between_names + (len(learning_rates) - 1) * (bar_width + distance_between_optimizers) / 2)\n",
    "ax.set_xticklabels(optimizers)\n",
    "\n",
    "# Add legend with adjusted position and ordered values\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "unique_labels = list(set(labels))\n",
    "# Order values in the legend\n",
    "ordered_values = ['0.01', '0.001', '0.0001']\n",
    "# Create a dictionary to map old labels to new labels\n",
    "label_mapping = {f'LR: {value}': f'LR: {value}' for value in ordered_values}\n",
    "new_labels = [label_mapping[label] for label in labels]\n",
    "# Plot the legend\n",
    "ax.legend(handles[:len(learning_rates)], new_labels, title='Learning Rate', bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "# Save the plot\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "plot_filename = os.path.join(output_directory, 'comparative_analysis_VGG19.png')\n",
    "plt.savefig(plot_filename, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f682146-9d82-4363-98b6-767a50525637",
   "metadata": {},
   "source": [
    "# COMPARATIVE ANALYSIS OF ALL 45 MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee463c-53f7-4b70-acaf-97149d0ab1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Average metric formulas for DenseNet201\n",
    "average_test_accuracy_DenseNet201 = (test_accuracy_DenseNet201_ADAM_01 + test_accuracy_DenseNet201_ADAM_001 + test_accuracy_DenseNet201_ADAM_0001 +\n",
    "                                     test_accuracy_DenseNet201_SGD_01 + test_accuracy_DenseNet201_SGD_001 + test_accuracy_DenseNet201_SGD_0001 +\n",
    "                                     test_accuracy_DenseNet201_RMSprop_01 + test_accuracy_DenseNet201_RMSprop_001 + test_accuracy_DenseNet201_RMSprop_0001) / 9\n",
    "\n",
    "average_test_precision_DenseNet201 = (test_precision_DenseNet201_ADAM_01 + test_precision_DenseNet201_ADAM_001 + test_precision_DenseNet201_ADAM_0001 +\n",
    "                                      test_precision_DenseNet201_SGD_01 + test_precision_DenseNet201_SGD_001 + test_precision_DenseNet201_SGD_0001 +\n",
    "                                      test_precision_DenseNet201_RMSprop_01 + test_precision_DenseNet201_RMSprop_001 + test_precision_DenseNet201_RMSprop_0001) / 9\n",
    "\n",
    "average_test_recall_DenseNet201 = (test_recall_DenseNet201_ADAM_01 + test_recall_DenseNet201_ADAM_001 + test_recall_DenseNet201_ADAM_0001 +\n",
    "                                   test_recall_DenseNet201_SGD_01 + test_recall_DenseNet201_SGD_001 + test_recall_DenseNet201_SGD_0001 +\n",
    "                                   test_recall_DenseNet201_RMSprop_01 + test_recall_DenseNet201_RMSprop_001 + test_recall_DenseNet201_RMSprop_0001) / 9\n",
    "\n",
    "average_test_cohen_kappa_DenseNet201 = (test_cohen_kappa_DenseNet201_ADAM_01 + test_cohen_kappa_DenseNet201_ADAM_001 + test_cohen_kappa_DenseNet201_ADAM_0001 +\n",
    "                                   test_cohen_kappa_DenseNet201_SGD_01 + test_cohen_kappa_DenseNet201_SGD_001 + test_cohen_kappa_DenseNet201_SGD_0001 +\n",
    "                                   test_cohen_kappa_DenseNet201_RMSprop_01 + test_cohen_kappa_DenseNet201_RMSprop_001 + test_cohen_kappa_DenseNet201_RMSprop_0001) / 9\n",
    "\n",
    "average_test_jaccard_index_DenseNet201 = (test_jaccard_index_DenseNet201_ADAM_01 + test_jaccard_index_DenseNet201_ADAM_001 + test_jaccard_index_DenseNet201_ADAM_0001 +\n",
    "                                   test_jaccard_index_DenseNet201_SGD_01 + test_jaccard_index_DenseNet201_SGD_001 + test_jaccard_index_DenseNet201_SGD_0001 +\n",
    "                                   test_jaccard_index_DenseNet201_RMSprop_01 + test_jaccard_index_DenseNet201_RMSprop_001 + test_jaccard_index_DenseNet201_RMSprop_0001) / 9\n",
    "\n",
    "# Average metric formulas for InceptionV3\n",
    "average_test_accuracy_InceptionV3 = (test_accuracy_InceptionV3_ADAM_01 + test_accuracy_InceptionV3_ADAM_001 + test_accuracy_InceptionV3_ADAM_0001 +\n",
    "                                      test_accuracy_InceptionV3_SGD_01 + test_accuracy_InceptionV3_SGD_001 + test_accuracy_InceptionV3_SGD_0001 +\n",
    "                                      test_accuracy_InceptionV3_RMSprop_01 + test_accuracy_InceptionV3_RMSprop_001 + test_accuracy_InceptionV3_RMSprop_0001) / 9\n",
    "\n",
    "average_test_precision_InceptionV3 = (test_precision_InceptionV3_ADAM_01 + test_precision_InceptionV3_ADAM_001 + test_precision_InceptionV3_ADAM_0001 +\n",
    "                                       test_precision_InceptionV3_SGD_01 + test_precision_InceptionV3_SGD_001 + test_precision_InceptionV3_SGD_0001 +\n",
    "                                       test_precision_InceptionV3_RMSprop_01 + test_precision_InceptionV3_RMSprop_001 + test_precision_InceptionV3_RMSprop_0001) / 9\n",
    "\n",
    "average_test_recall_InceptionV3 = (test_recall_InceptionV3_ADAM_01 + test_recall_InceptionV3_ADAM_001 + test_recall_InceptionV3_ADAM_0001 +\n",
    "                                    test_recall_InceptionV3_SGD_01 + test_recall_InceptionV3_SGD_001 + test_recall_InceptionV3_SGD_0001 +\n",
    "                                    test_recall_InceptionV3_RMSprop_01 + test_recall_InceptionV3_RMSprop_001 + test_recall_InceptionV3_RMSprop_0001) / 9\n",
    "\n",
    "average_test_cohen_kappa_InceptionV3 = (test_cohen_kappa_InceptionV3_ADAM_01 + test_cohen_kappa_InceptionV3_ADAM_001 + test_cohen_kappa_InceptionV3_ADAM_0001 +\n",
    "                                   test_cohen_kappa_InceptionV3_SGD_01 + test_cohen_kappa_InceptionV3_SGD_001 + test_cohen_kappa_InceptionV3_SGD_0001 +\n",
    "                                   test_cohen_kappa_InceptionV3_RMSprop_01 + test_cohen_kappa_InceptionV3_RMSprop_001 + test_cohen_kappa_InceptionV3_RMSprop_0001) / 9\n",
    "\n",
    "average_test_jaccard_index_InceptionV3 = (test_jaccard_index_InceptionV3_ADAM_01 + test_jaccard_index_InceptionV3_ADAM_001 + test_jaccard_index_InceptionV3_ADAM_0001 +\n",
    "                                   test_jaccard_index_InceptionV3_SGD_01 + test_jaccard_index_InceptionV3_SGD_001 + test_jaccard_index_InceptionV3_SGD_0001 +\n",
    "                                   test_jaccard_index_InceptionV3_RMSprop_01 + test_jaccard_index_InceptionV3_RMSprop_001 + test_jaccard_index_InceptionV3_RMSprop_0001) / 9\n",
    "\n",
    "# Average metric formulas for MobileNetV2\n",
    "average_test_accuracy_MobileNetV2 = (test_accuracy_MobileNetV2_ADAM_01 + test_accuracy_MobileNetV2_ADAM_001 + test_accuracy_MobileNetV2_ADAM_0001 +\n",
    "                                      test_accuracy_MobileNetV2_SGD_01 + test_accuracy_MobileNetV2_SGD_001 + test_accuracy_MobileNetV2_SGD_0001 +\n",
    "                                      test_accuracy_MobileNetV2_RMSprop_01 + test_accuracy_MobileNetV2_RMSprop_001 + test_accuracy_MobileNetV2_RMSprop_0001) / 9\n",
    "\n",
    "average_test_precision_MobileNetV2 = (test_precision_MobileNetV2_ADAM_01 + test_precision_MobileNetV2_ADAM_001 + test_precision_MobileNetV2_ADAM_0001 +\n",
    "                                       test_precision_MobileNetV2_SGD_01 + test_precision_MobileNetV2_SGD_001 + test_precision_MobileNetV2_SGD_0001 +\n",
    "                                       test_precision_MobileNetV2_RMSprop_01 + test_precision_MobileNetV2_RMSprop_001 + test_precision_MobileNetV2_RMSprop_0001) / 9\n",
    "\n",
    "average_test_recall_MobileNetV2 = (test_recall_MobileNetV2_ADAM_01 + test_recall_MobileNetV2_ADAM_001 + test_recall_MobileNetV2_ADAM_0001 +\n",
    "                                    test_recall_MobileNetV2_SGD_01 + test_recall_MobileNetV2_SGD_001 + test_recall_MobileNetV2_SGD_0001 +\n",
    "                                    test_recall_MobileNetV2_RMSprop_01 + test_recall_MobileNetV2_RMSprop_001 + test_recall_MobileNetV2_RMSprop_0001) / 9\n",
    "\n",
    "average_test_cohen_kappa_MobileNetV2 = (test_cohen_kappa_MobileNetV2_ADAM_01 + test_cohen_kappa_MobileNetV2_ADAM_001 + test_cohen_kappa_MobileNetV2_ADAM_0001 +\n",
    "                                   test_cohen_kappa_MobileNetV2_SGD_01 + test_cohen_kappa_MobileNetV2_SGD_001 + test_cohen_kappa_MobileNetV2_SGD_0001 +\n",
    "                                   test_cohen_kappa_MobileNetV2_RMSprop_01 + test_cohen_kappa_MobileNetV2_RMSprop_001 + test_cohen_kappa_MobileNetV2_RMSprop_0001) / 9\n",
    "\n",
    "average_test_jaccard_index_MobileNetV2 = (test_jaccard_index_MobileNetV2_ADAM_01 + test_jaccard_index_MobileNetV2_ADAM_001 + test_jaccard_index_MobileNetV2_ADAM_0001 +\n",
    "                                   test_jaccard_index_MobileNetV2_SGD_01 + test_jaccard_index_MobileNetV2_SGD_001 + test_jaccard_index_MobileNetV2_SGD_0001 +\n",
    "                                   test_jaccard_index_MobileNetV2_RMSprop_01 + test_jaccard_index_MobileNetV2_RMSprop_001 + test_jaccard_index_MobileNetV2_RMSprop_0001) / 9\n",
    "\n",
    "# Average metric formulas for ResNet50\n",
    "average_test_accuracy_ResNet50 = (test_accuracy_ResNet50_ADAM_01 + test_accuracy_ResNet50_ADAM_001 + test_accuracy_ResNet50_ADAM_0001 +\n",
    "                                   test_accuracy_ResNet50_SGD_01 + test_accuracy_ResNet50_SGD_001 + test_accuracy_ResNet50_SGD_0001 +\n",
    "                                   test_accuracy_ResNet50_RMSprop_01 + test_accuracy_ResNet50_RMSprop_001 + test_accuracy_ResNet50_RMSprop_0001) / 9\n",
    "\n",
    "average_test_precision_ResNet50 = (test_precision_ResNet50_ADAM_01 + test_precision_ResNet50_ADAM_001 + test_precision_ResNet50_ADAM_0001 +\n",
    "                                    test_precision_ResNet50_SGD_01 + test_precision_ResNet50_SGD_001 + test_precision_ResNet50_SGD_0001 +\n",
    "                                    test_precision_ResNet50_RMSprop_01 + test_precision_ResNet50_RMSprop_001 + test_precision_ResNet50_RMSprop_0001) / 9\n",
    "\n",
    "average_test_recall_ResNet50 = (test_recall_ResNet50_ADAM_01 + test_recall_ResNet50_ADAM_001 + test_recall_ResNet50_ADAM_0001 +\n",
    "                                 test_recall_ResNet50_SGD_01 + test_recall_ResNet50_SGD_001 + test_recall_ResNet50_SGD_0001 +\n",
    "                                 test_recall_ResNet50_RMSprop_01 + test_recall_ResNet50_RMSprop_001 + test_recall_ResNet50_RMSprop_0001) / 9\n",
    "\n",
    "average_test_cohen_kappa_ResNet50 = (test_cohen_kappa_ResNet50_ADAM_01 + test_cohen_kappa_ResNet50_ADAM_001 + test_cohen_kappa_ResNet50_ADAM_0001 +\n",
    "                                   test_cohen_kappa_ResNet50_SGD_01 + test_cohen_kappa_ResNet50_SGD_001 + test_cohen_kappa_ResNet50_SGD_0001 +\n",
    "                                   test_cohen_kappa_ResNet50_RMSprop_01 + test_cohen_kappa_ResNet50_RMSprop_001 + test_cohen_kappa_ResNet50_RMSprop_0001) / 9\n",
    "\n",
    "average_test_jaccard_index_ResNet50 = (test_jaccard_index_ResNet50_ADAM_01 + test_jaccard_index_ResNet50_ADAM_001 + test_jaccard_index_ResNet50_ADAM_0001 +\n",
    "                                   test_jaccard_index_ResNet50_SGD_01 + test_jaccard_index_ResNet50_SGD_001 + test_jaccard_index_ResNet50_SGD_0001 +\n",
    "                                   test_jaccard_index_ResNet50_RMSprop_01 + test_jaccard_index_ResNet50_RMSprop_001 + test_jaccard_index_ResNet50_RMSprop_0001) / 9\n",
    "\n",
    "# Average metric formulas for VGG19\n",
    "average_test_accuracy_VGG19 = (test_accuracy_VGG19_ADAM_01 + test_accuracy_VGG19_ADAM_001 + test_accuracy_VGG19_ADAM_0001 +\n",
    "                               test_accuracy_VGG19_SGD_01 + test_accuracy_VGG19_SGD_001 + test_accuracy_VGG19_SGD_0001 +\n",
    "                               test_accuracy_VGG19_RMSprop_01 + test_accuracy_VGG19_RMSprop_001 + test_accuracy_VGG19_RMSprop_0001) / 9\n",
    "\n",
    "average_test_precision_VGG19 = (test_precision_VGG19_ADAM_01 + test_precision_VGG19_ADAM_001 + test_precision_VGG19_ADAM_0001 +\n",
    "                                test_precision_VGG19_SGD_01 + test_precision_VGG19_SGD_001 + test_precision_VGG19_SGD_0001 +\n",
    "                                test_precision_VGG19_RMSprop_01 + test_precision_VGG19_RMSprop_001 + test_precision_VGG19_RMSprop_0001) / 9\n",
    "\n",
    "average_test_recall_VGG19 = (test_recall_VGG19_ADAM_01 + test_recall_VGG19_ADAM_001 + test_recall_VGG19_ADAM_0001 +\n",
    "                             test_recall_VGG19_SGD_01 + test_recall_VGG19_SGD_001 + test_recall_VGG19_SGD_0001 +\n",
    "                             test_recall_VGG19_RMSprop_01 + test_recall_VGG19_RMSprop_001 + test_recall_VGG19_RMSprop_0001) / 9\n",
    "\n",
    "average_test_cohen_kappa_VGG19 = (test_cohen_kappa_VGG19_ADAM_01 + test_cohen_kappa_VGG19_ADAM_001 + test_cohen_kappa_VGG19_ADAM_0001 +\n",
    "                                   test_cohen_kappa_VGG19_SGD_01 + test_cohen_kappa_VGG19_SGD_001 + test_cohen_kappa_VGG19_SGD_0001 +\n",
    "                                   test_cohen_kappa_VGG19_RMSprop_01 + test_cohen_kappa_VGG19_RMSprop_001 + test_cohen_kappa_VGG19_RMSprop_0001) / 9\n",
    "\n",
    "average_test_jaccard_index_VGG19 = (test_jaccard_index_VGG19_ADAM_01 + test_jaccard_index_VGG19_ADAM_001 + test_jaccard_index_VGG19_ADAM_0001 +\n",
    "                                   test_jaccard_index_VGG19_SGD_01 + test_jaccard_index_VGG19_SGD_001 + test_jaccard_index_VGG19_SGD_0001 +\n",
    "                                   test_jaccard_index_VGG19_RMSprop_01 + test_jaccard_index_VGG19_RMSprop_001 + test_jaccard_index_VGG19_RMSprop_0001) / 9\n",
    "\n",
    "# List of models\n",
    "models = ['DenseNet201', 'InceptionV3', 'MobileNetV2', 'ResNet50', 'VGG19']\n",
    "\n",
    "# Corresponding lists of average accuracy, precision, and recall values\n",
    "average_test_accuracies = [\n",
    "    average_test_accuracy_DenseNet201,\n",
    "    average_test_accuracy_InceptionV3,\n",
    "    average_test_accuracy_MobileNetV2,\n",
    "    average_test_accuracy_ResNet50,\n",
    "    average_test_accuracy_VGG19\n",
    "]\n",
    "\n",
    "average_test_precisions = [\n",
    "    average_test_precision_DenseNet201,\n",
    "    average_test_precision_InceptionV3,\n",
    "    average_test_precision_MobileNetV2,\n",
    "    average_test_precision_ResNet50,\n",
    "    average_test_precision_VGG19\n",
    "]\n",
    "\n",
    "average_test_recalls = [\n",
    "    average_test_recall_DenseNet201,\n",
    "    average_test_recall_InceptionV3,\n",
    "    average_test_recall_MobileNetV2,\n",
    "    average_test_recall_ResNet50,\n",
    "    average_test_recall_VGG19\n",
    "]\n",
    "\n",
    "average_test_cohen_kappas = [\n",
    "    average_test_cohen_kappa_DenseNet201,\n",
    "    average_test_cohen_kappa_InceptionV3,\n",
    "    average_test_cohen_kappa_MobileNetV2,\n",
    "    average_test_cohen_kappa_ResNet50,\n",
    "    average_test_cohen_kappa_VGG19\n",
    "]\n",
    "\n",
    "average_test_jaccard_indexs = [\n",
    "    average_test_jaccard_index_DenseNet201,\n",
    "    average_test_jaccard_index_InceptionV3,\n",
    "    average_test_jaccard_index_MobileNetV2,\n",
    "    average_test_jaccard_index_ResNet50,\n",
    "    average_test_jaccard_index_VGG19\n",
    "]\n",
    "\n",
    "\n",
    "# Plot bar graphs\n",
    "x = np.arange(len(models))  # the label locations\n",
    "width = 0.15  # the width of the bars\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "# Create the first y-axis for accuracy, precision, and recall\n",
    "ax1.set_xlabel('Model')\n",
    "ax1.set_ylabel('Scores')\n",
    "ax1.set_title('Model Performance Evaluation')\n",
    "\n",
    "# Assign different colors to each metric\n",
    "colors = ['blue', 'green', 'orange', 'red', 'purple']\n",
    "\n",
    "rects1 = ax1.bar(x - 2 * width, average_test_accuracies, width, label='Average Accuracy', color=colors[0])\n",
    "rects2 = ax1.bar(x - width, average_test_precisions, width, label='Average Precision', color=colors[1])\n",
    "rects3 = ax1.bar(x, average_test_recalls, width, label='Average Recall', color=colors[2])\n",
    "\n",
    "# Create a second y-axis for Cohen's Kappa and Jaccard Index\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Scores (Cohen\\'s Kappa and Jaccard Index)')\n",
    "\n",
    "rects4 = ax2.bar(x + width, average_test_cohen_kappas, width, label='Average Cohen\\'s Kappa', color=colors[3])\n",
    "rects5 = ax2.bar(x + 2 * width, average_test_jaccard_indexs, width, label='Average Jaccard Index', color=colors[4])\n",
    "\n",
    "# Combine all metrics in a single legend at the bottom\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='lower center', bbox_to_anchor=(0.5, -0.25), ncol=5)\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels, etc.\n",
    "ax1.set_xticks(x - width / 2)\n",
    "ax1.set_xticklabels(models)\n",
    "\n",
    "# Move the legend to the side\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "output_directory = 'results'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "plot_filename = os.path.join(output_directory, 'average_model_performance_evaluation.png')\n",
    "plt.savefig(plot_filename, bbox_inches='tight')  # Use bbox_inches to include the legends\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
